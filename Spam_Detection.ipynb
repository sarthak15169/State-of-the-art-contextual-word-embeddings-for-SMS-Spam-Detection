{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Detection.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_erc8qDRRF65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b83c842e-4fa2-4541-8fd6-4154ddf1b57a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vOM7ov-FQhhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "di1JOh-URdK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2bead84c-0d98-46f0-b537-17c67c75105c"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/Colab Notebooks/sms-spam-collection-dataset'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " dev.csv\t spam.csv\t\t test.csv    train.py\n",
            " preprocess.py\t'Spam Detection.ipynb'\t train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJ4ANu2pQK7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3666
        },
        "outputId": "de48c13d-ad49-4a79-9632-f3056da80b26"
      },
      "cell_type": "code",
      "source": [
        "import flair\n",
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "corpus = NLPTaskDataFetcher.load_classification_corpus(Path('/content/drive/My Drive/Colab Notebooks/sms-spam-collection-dataset'), test_file='test.csv', dev_file='dev.csv', train_file='train.csv')\n",
        "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), FlairEmbeddings('news-backward-fast')]\n",
        "document_embeddings = DocumentLSTMEmbeddings(word_embeddings, hidden_size=512, reproject_words=True, reproject_words_dimension=256)\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(), multi_label=False)\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train('./', max_epochs=10)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:06,440 Reading data from /content/drive/My Drive/Colab Notebooks/sms-spam-collection-dataset\n",
            "2019-05-01 12:03:06,446 Train: /content/drive/My Drive/Colab Notebooks/sms-spam-collection-dataset/train.csv\n",
            "2019-05-01 12:03:06,449 Dev: /content/drive/My Drive/Colab Notebooks/sms-spam-collection-dataset/dev.csv\n",
            "2019-05-01 12:03:06,450 Test: /content/drive/My Drive/Colab Notebooks/sms-spam-collection-dataset/test.csv\n",
            "2019-05-01 12:03:10,371 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmppm0dmvcr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:02<00:00, 70897742.68B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:12,838 copying /tmp/tmppm0dmvcr to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:13,316 removing temp file /tmp/tmppm0dmvcr\n",
            "2019-05-01 12:03:13,403 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpqhqexwj1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:00<00:00, 55560326.29B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:13,963 copying /tmp/tmpqhqexwj1 to cache at /root/.flair/embeddings/glove.gensim\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:14,009 removing temp file /tmp/tmpqhqexwj1\n",
            "2019-05-01 12:03:14,013 this function is deprecated, use smart_open.open instead\n",
            "2019-05-01 12:03:15,737 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpzp528b7t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 56468783.89B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:16,229 copying /tmp/tmpzp528b7t to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2019-05-01 12:03:16,261 removing temp file /tmp/tmpzp528b7t\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:23,179 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpxrvtjxe8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:00<00:00, 55003552.45B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:23,714 copying /tmp/tmpxrvtjxe8 to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2019-05-01 12:03:23,738 removing temp file /tmp/tmpxrvtjxe8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:23,837 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:03:23,838 Evaluation method: MICRO_F1_SCORE\n",
            "2019-05-01 12:03:23,839 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:03:24,049 epoch 1 - iter 0/130 - loss 0.02400812\n",
            "2019-05-01 12:03:26,072 epoch 1 - iter 13/130 - loss 0.00919320\n",
            "2019-05-01 12:03:27,999 epoch 1 - iter 26/130 - loss 0.00875237\n",
            "2019-05-01 12:03:30,120 epoch 1 - iter 39/130 - loss 0.00727622\n",
            "2019-05-01 12:03:32,426 epoch 1 - iter 52/130 - loss 0.00671992\n",
            "2019-05-01 12:03:34,618 epoch 1 - iter 65/130 - loss 0.00622632\n",
            "2019-05-01 12:03:36,598 epoch 1 - iter 78/130 - loss 0.00573422\n",
            "2019-05-01 12:03:39,114 epoch 1 - iter 91/130 - loss 0.00536235\n",
            "2019-05-01 12:03:41,173 epoch 1 - iter 104/130 - loss 0.00522977\n",
            "2019-05-01 12:03:42,961 epoch 1 - iter 117/130 - loss 0.00490308\n",
            "2019-05-01 12:03:44,491 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:03:44,492 EPOCH 1 done: loss 0.0047 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:03:46,649 DEV  : loss 0.00295603 - f-score 0.9826 - acc 0.9658\n",
            "2019-05-01 12:03:49,336 TEST : loss 0.00321067 - f-score 0.9729 - acc 0.9473\n",
            "2019-05-01 12:03:53,218 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:03:53,310 epoch 2 - iter 0/130 - loss 0.00062845\n",
            "2019-05-01 12:03:54,150 epoch 2 - iter 13/130 - loss 0.00248262\n",
            "2019-05-01 12:03:55,013 epoch 2 - iter 26/130 - loss 0.00358403\n",
            "2019-05-01 12:03:55,905 epoch 2 - iter 39/130 - loss 0.00341336\n",
            "2019-05-01 12:03:56,768 epoch 2 - iter 52/130 - loss 0.00309776\n",
            "2019-05-01 12:03:57,618 epoch 2 - iter 65/130 - loss 0.00287105\n",
            "2019-05-01 12:03:58,567 epoch 2 - iter 78/130 - loss 0.00251323\n",
            "2019-05-01 12:03:59,461 epoch 2 - iter 91/130 - loss 0.00249200\n",
            "2019-05-01 12:04:00,362 epoch 2 - iter 104/130 - loss 0.00248842\n",
            "2019-05-01 12:04:01,210 epoch 2 - iter 117/130 - loss 0.00249616\n",
            "2019-05-01 12:04:02,036 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:02,037 EPOCH 2 done: loss 0.0025 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:04:02,928 DEV  : loss 0.01108630 - f-score 0.9362 - acc 0.8800\n",
            "2019-05-01 12:04:03,851 TEST : loss 0.00963369 - f-score 0.9381 - acc 0.8834\n",
            "2019-05-01 12:04:07,582 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:07,673 epoch 3 - iter 0/130 - loss 0.01575892\n",
            "2019-05-01 12:04:08,621 epoch 3 - iter 13/130 - loss 0.00319275\n",
            "2019-05-01 12:04:09,516 epoch 3 - iter 26/130 - loss 0.00252939\n",
            "2019-05-01 12:04:10,437 epoch 3 - iter 39/130 - loss 0.00220672\n",
            "2019-05-01 12:04:11,339 epoch 3 - iter 52/130 - loss 0.00192356\n",
            "2019-05-01 12:04:12,236 epoch 3 - iter 65/130 - loss 0.00180708\n",
            "2019-05-01 12:04:13,065 epoch 3 - iter 78/130 - loss 0.00169469\n",
            "2019-05-01 12:04:13,984 epoch 3 - iter 91/130 - loss 0.00208613\n",
            "2019-05-01 12:04:14,918 epoch 3 - iter 104/130 - loss 0.00198409\n",
            "2019-05-01 12:04:15,839 epoch 3 - iter 117/130 - loss 0.00203313\n",
            "2019-05-01 12:04:16,680 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:16,682 EPOCH 3 done: loss 0.0022 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:04:17,612 DEV  : loss 0.00597212 - f-score 0.9594 - acc 0.9219\n",
            "2019-05-01 12:04:18,729 TEST : loss 0.00562195 - f-score 0.9594 - acc 0.9219\n",
            "2019-05-01 12:04:23,258 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:23,348 epoch 4 - iter 0/130 - loss 0.00245490\n",
            "2019-05-01 12:04:24,402 epoch 4 - iter 13/130 - loss 0.00152147\n",
            "2019-05-01 12:04:25,513 epoch 4 - iter 26/130 - loss 0.00189188\n",
            "2019-05-01 12:04:26,542 epoch 4 - iter 39/130 - loss 0.00174647\n",
            "2019-05-01 12:04:27,601 epoch 4 - iter 52/130 - loss 0.00153989\n",
            "2019-05-01 12:04:28,572 epoch 4 - iter 65/130 - loss 0.00159613\n",
            "2019-05-01 12:04:29,481 epoch 4 - iter 78/130 - loss 0.00148780\n",
            "2019-05-01 12:04:30,412 epoch 4 - iter 91/130 - loss 0.00161973\n",
            "2019-05-01 12:04:31,406 epoch 4 - iter 104/130 - loss 0.00171804\n",
            "2019-05-01 12:04:32,280 epoch 4 - iter 117/130 - loss 0.00180378\n",
            "2019-05-01 12:04:33,047 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:33,049 EPOCH 4 done: loss 0.0018 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:04:33,966 DEV  : loss 0.00183367 - f-score 0.9826 - acc 0.9658\n",
            "2019-05-01 12:04:34,997 TEST : loss 0.00271753 - f-score 0.9787 - acc 0.9583\n",
            "2019-05-01 12:04:38,623 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:38,699 epoch 5 - iter 0/130 - loss 0.00010359\n",
            "2019-05-01 12:04:39,671 epoch 5 - iter 13/130 - loss 0.00320669\n",
            "2019-05-01 12:04:40,600 epoch 5 - iter 26/130 - loss 0.00228585\n",
            "2019-05-01 12:04:41,536 epoch 5 - iter 39/130 - loss 0.00190552\n",
            "2019-05-01 12:04:42,399 epoch 5 - iter 52/130 - loss 0.00159841\n",
            "2019-05-01 12:04:43,356 epoch 5 - iter 65/130 - loss 0.00158316\n",
            "2019-05-01 12:04:44,224 epoch 5 - iter 78/130 - loss 0.00148338\n",
            "2019-05-01 12:04:45,157 epoch 5 - iter 91/130 - loss 0.00151224\n",
            "2019-05-01 12:04:46,071 epoch 5 - iter 104/130 - loss 0.00148037\n",
            "2019-05-01 12:04:47,015 epoch 5 - iter 117/130 - loss 0.00152214\n",
            "2019-05-01 12:04:47,811 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:47,812 EPOCH 5 done: loss 0.0016 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:04:48,732 DEV  : loss 0.00216671 - f-score 0.9826 - acc 0.9658\n",
            "2019-05-01 12:04:49,758 TEST : loss 0.00302734 - f-score 0.9768 - acc 0.9546\n",
            "2019-05-01 12:04:53,833 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:04:53,927 epoch 6 - iter 0/130 - loss 0.00102411\n",
            "2019-05-01 12:04:54,989 epoch 6 - iter 13/130 - loss 0.00224239\n",
            "2019-05-01 12:04:56,005 epoch 6 - iter 26/130 - loss 0.00221412\n",
            "2019-05-01 12:04:57,065 epoch 6 - iter 39/130 - loss 0.00189600\n",
            "2019-05-01 12:04:58,060 epoch 6 - iter 52/130 - loss 0.00171197\n",
            "2019-05-01 12:04:59,102 epoch 6 - iter 65/130 - loss 0.00159087\n",
            "2019-05-01 12:05:00,135 epoch 6 - iter 78/130 - loss 0.00157928\n",
            "2019-05-01 12:05:00,986 epoch 6 - iter 91/130 - loss 0.00144958\n",
            "2019-05-01 12:05:01,908 epoch 6 - iter 104/130 - loss 0.00130327\n",
            "2019-05-01 12:05:02,808 epoch 6 - iter 117/130 - loss 0.00143711\n",
            "2019-05-01 12:05:03,588 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:03,589 EPOCH 6 done: loss 0.0016 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:05:04,517 DEV  : loss 0.00167050 - f-score 0.9845 - acc 0.9695\n",
            "2019-05-01 12:05:05,551 TEST : loss 0.00254612 - f-score 0.9787 - acc 0.9583\n",
            "2019-05-01 12:05:05,553 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:05,629 epoch 7 - iter 0/130 - loss 0.00005341\n",
            "2019-05-01 12:05:06,535 epoch 7 - iter 13/130 - loss 0.00045514\n",
            "2019-05-01 12:05:07,495 epoch 7 - iter 26/130 - loss 0.00068334\n",
            "2019-05-01 12:05:08,423 epoch 7 - iter 39/130 - loss 0.00058549\n",
            "2019-05-01 12:05:09,348 epoch 7 - iter 52/130 - loss 0.00057177\n",
            "2019-05-01 12:05:10,270 epoch 7 - iter 65/130 - loss 0.00060487\n",
            "2019-05-01 12:05:11,186 epoch 7 - iter 78/130 - loss 0.00080045\n",
            "2019-05-01 12:05:12,084 epoch 7 - iter 91/130 - loss 0.00083189\n",
            "2019-05-01 12:05:13,018 epoch 7 - iter 104/130 - loss 0.00116600\n",
            "2019-05-01 12:05:13,926 epoch 7 - iter 117/130 - loss 0.00119763\n",
            "2019-05-01 12:05:14,679 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:14,681 EPOCH 7 done: loss 0.0013 - lr 0.1000 - bad epochs 1\n",
            "2019-05-01 12:05:15,609 DEV  : loss 0.00409088 - f-score 0.9555 - acc 0.9148\n",
            "2019-05-01 12:05:16,637 TEST : loss 0.00560991 - f-score 0.9478 - acc 0.9007\n",
            "2019-05-01 12:05:20,387 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:20,494 epoch 8 - iter 0/130 - loss 0.00888110\n",
            "2019-05-01 12:05:21,436 epoch 8 - iter 13/130 - loss 0.00206639\n",
            "2019-05-01 12:05:22,403 epoch 8 - iter 26/130 - loss 0.00135615\n",
            "2019-05-01 12:05:23,317 epoch 8 - iter 39/130 - loss 0.00114267\n",
            "2019-05-01 12:05:24,131 epoch 8 - iter 52/130 - loss 0.00115122\n",
            "2019-05-01 12:05:25,063 epoch 8 - iter 65/130 - loss 0.00106993\n",
            "2019-05-01 12:05:26,033 epoch 8 - iter 78/130 - loss 0.00096952\n",
            "2019-05-01 12:05:26,915 epoch 8 - iter 91/130 - loss 0.00101842\n",
            "2019-05-01 12:05:27,776 epoch 8 - iter 104/130 - loss 0.00096879\n",
            "2019-05-01 12:05:28,646 epoch 8 - iter 117/130 - loss 0.00106985\n",
            "2019-05-01 12:05:29,516 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:29,517 EPOCH 8 done: loss 0.0011 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:05:30,447 DEV  : loss 0.00165694 - f-score 0.9807 - acc 0.9620\n",
            "2019-05-01 12:05:31,487 TEST : loss 0.00291341 - f-score 0.9768 - acc 0.9546\n",
            "2019-05-01 12:05:35,093 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:35,171 epoch 9 - iter 0/130 - loss 0.00047523\n",
            "2019-05-01 12:05:36,106 epoch 9 - iter 13/130 - loss 0.00057847\n",
            "2019-05-01 12:05:37,053 epoch 9 - iter 26/130 - loss 0.00078157\n",
            "2019-05-01 12:05:38,035 epoch 9 - iter 39/130 - loss 0.00069927\n",
            "2019-05-01 12:05:38,913 epoch 9 - iter 52/130 - loss 0.00094765\n",
            "2019-05-01 12:05:39,839 epoch 9 - iter 65/130 - loss 0.00102291\n",
            "2019-05-01 12:05:40,746 epoch 9 - iter 78/130 - loss 0.00112061\n",
            "2019-05-01 12:05:41,647 epoch 9 - iter 91/130 - loss 0.00110614\n",
            "2019-05-01 12:05:42,561 epoch 9 - iter 104/130 - loss 0.00116890\n",
            "2019-05-01 12:05:43,489 epoch 9 - iter 117/130 - loss 0.00113585\n",
            "2019-05-01 12:05:44,267 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:44,268 EPOCH 9 done: loss 0.0011 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:05:45,193 DEV  : loss 0.00169222 - f-score 0.9845 - acc 0.9695\n",
            "2019-05-01 12:05:46,222 TEST : loss 0.00271980 - f-score 0.9787 - acc 0.9583\n",
            "2019-05-01 12:05:49,865 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:49,968 epoch 10 - iter 0/130 - loss 0.00232509\n",
            "2019-05-01 12:05:50,926 epoch 10 - iter 13/130 - loss 0.00066447\n",
            "2019-05-01 12:05:51,817 epoch 10 - iter 26/130 - loss 0.00097126\n",
            "2019-05-01 12:05:52,742 epoch 10 - iter 39/130 - loss 0.00079273\n",
            "2019-05-01 12:05:53,665 epoch 10 - iter 52/130 - loss 0.00093038\n",
            "2019-05-01 12:05:54,582 epoch 10 - iter 65/130 - loss 0.00087467\n",
            "2019-05-01 12:05:55,437 epoch 10 - iter 78/130 - loss 0.00098269\n",
            "2019-05-01 12:05:56,382 epoch 10 - iter 91/130 - loss 0.00103711\n",
            "2019-05-01 12:05:57,298 epoch 10 - iter 104/130 - loss 0.00115958\n",
            "2019-05-01 12:05:58,177 epoch 10 - iter 117/130 - loss 0.00114566\n",
            "2019-05-01 12:05:58,982 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:05:58,986 EPOCH 10 done: loss 0.0011 - lr 0.1000 - bad epochs 0\n",
            "2019-05-01 12:05:59,916 DEV  : loss 0.00187521 - f-score 0.9845 - acc 0.9695\n",
            "2019-05-01 12:06:00,945 TEST : loss 0.00288076 - f-score 0.9768 - acc 0.9546\n",
            "2019-05-01 12:06:04,757 ----------------------------------------------------------------------------------------------------\n",
            "2019-05-01 12:06:04,758 Testing using best model ...\n",
            "2019-05-01 12:06:04,759 loading file best-model.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:542: DeprecationWarning: Call to deprecated class DocumentLSTMEmbeddings. (The functionality of this class is moved to 'DocumentRNNEmbeddings') -- Deprecated since version 0.4.\n",
            "  result = unpickler.load()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-05-01 12:06:07,210 MICRO_AVG: acc 0.9583 - f1-score 0.9787\n",
            "2019-05-01 12:06:07,212 MACRO_AVG: acc 0.9035 - f1-score 0.9478\n",
            "2019-05-01 12:06:07,213 ham        tp: 452 - fp: 8 - fn: 3 - tn: 54 - precision: 0.9826 - recall: 0.9934 - accuracy: 0.9762 - f1-score: 0.9880\n",
            "2019-05-01 12:06:07,215 spam       tp: 54 - fp: 3 - fn: 8 - tn: 452 - precision: 0.9474 - recall: 0.8710 - accuracy: 0.8308 - f1-score: 0.9076\n",
            "2019-05-01 12:06:07,216 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [0.0029560334514826536,\n",
              "  0.01108629908412695,\n",
              "  0.005972117651253939,\n",
              "  0.0018336725188419223,\n",
              "  0.002166712423786521,\n",
              "  0.0016705009620636702,\n",
              "  0.004090881906449795,\n",
              "  0.0016569423023611307,\n",
              "  0.0016922238282859325,\n",
              "  0.0018752125324681401],\n",
              " 'dev_score_history': [0.9826,\n",
              "  0.9362,\n",
              "  0.9594,\n",
              "  0.9826,\n",
              "  0.9826,\n",
              "  0.9845,\n",
              "  0.9555,\n",
              "  0.9807,\n",
              "  0.9845,\n",
              "  0.9845],\n",
              " 'test_score': 0.9787,\n",
              " 'train_loss_history': [0.0047158028781774395,\n",
              "  0.0025409793170414496,\n",
              "  0.002176696823587801,\n",
              "  0.001834704099931645,\n",
              "  0.001559152054130815,\n",
              "  0.0016104306571834248,\n",
              "  0.0012871259163520067,\n",
              "  0.001100292878434909,\n",
              "  0.0010622567645985827,\n",
              "  0.0010752558090429563]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}